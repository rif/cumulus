<html>
<head>
<meta pid="KameiRevisiting-CameraReady" track="Research" title="Revisiting Common Bug Prediction Findings Using Effort-Aware Models" presenter="Yasutaka Kamei" authors="Yasutaka Kamei,Shinsuke Matsumoto,Akito Monden,Ken-ichi Matsumoto,Bram Adams,Ahmed E. Hassan" location="D1" date="16-09-2010 14:00"/>
<title>Revisiting Common Bug Prediction Findings Using Effort-Aware Models</title>
<meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no" />
<link rel="stylesheet" href="../../css/paperstyle.css" type="text/css">
</head>
<body>
<h2>Revisiting Common Bug Prediction Findings Using Effort-Aware Models</h2>
<small class="alt"> Thursday, 16-09-2010 - 14:00 location: D1</small>
<hr>
<h4 class="alt">Authors: Yasutaka Kamei, Shinsuke Matsumoto, Akito Monden, Ken-ichi Matsumoto, Bram Adams and Ahmed E. Hassan</h4>
<p>
Bug prediction models are often used to help allocate software quality assurance efforts (e.g. testing and code reviews). Mende and Koschke have recently proposed bug prediction models that are effort-aware. These models factor in the effort needed to review or test code when evaluating the effectiveness of prediction models, leading to more realistic performance evaluations. In this paper, we revisit two common findings in the bug prediction literature: 1) Process metrics (e.g., change history) outperform product metrics (e.g., LOC), 2) Package- level predictions outperform file-level predictions. Through a case study on three projects from the Eclipse Foundation, we find that the first finding holds when effort is considered, while the second finding does not hold. These findings validate the practical significance of prior findings in the bug prediction literature and encourage their adoption in practice.

</p>
<br/>

</body>
</html>